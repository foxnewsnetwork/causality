# July  19, 2021 Work Diary

In [this youtube video](https://www.youtube.com/watch?v=ojjzXyQCzso), math youtuber 3blue1brown's Grant Sanderson posed a challenge for the math community to create an education video which explains some math concept. 

Since I've been on-and-off trying to learn the tools of the mathematics of causality, I'd like to take this opportunity to put together something to go over what I've learned.

This document will be the content outline of the video I intend to produce

## Topic: the math of understanding

### start with motivation

Democritus is an ancient greek philosopher known today for being an OG atomist and famouse quote from him is:

> I would rather discover one causal law than be King of Persia

we interpret this to mean that, for example, Democritus would have lead a fulfilling life if he could have done with his distant predesscor Pythagoras did by discovering the relationship of

a^2 + b^2 = c^2

discovery is like teaching, only instead of helping others understand something, the discoverer helps others understand something WHEN that something has never been understood before.

But what does it mean to understand?

In other words, if we have a computer, which as [this twitter user](https://twitter.com/daisyowl/status/841802094361235456?lang=en) puts so eloquently

> ... is a rock we tricked into thinking

how do we next "trick" it into understanding?

### a bit of history and CYA myself

The study of understanding, or the study of having / acquiring knowledge, is known as epistemology and dates as far back as Socrates over 2000 years ago and has been hotly debated.

And, judging by the utter lack of skynet robots enslaving us all into human visual processing / battery farms that our post-singularity AI overlords are suppose to subject us to, it's safe to say the debate is still going strong.

But sometime in the late 90s early 2000s, a group of researchers under Turing award winner Judea Pearl re-introduced a new approach to causal modeling that has taken the AI community by slow landslide. 

And when combined with neural networks, which has taken the AI community by storm, seems to finally have given us an understanding of understanding.

Now, being neither a professional mathematician nor an AI researcher, I'm instead a software programmer who makes a living coloring buttons and the like, and so I'm by no means an expert in this field. 

Still, here's hopefully an intro guide to causality as understandable by a beginner.

### concrete example: when your mom beats you

Consider the following series of events in no particular order

- it's 8pm and you run into the kitchen
- your mom warns "don't touch the pickle jar, you'll break it"
- you throw your mom's pickling jar onto the floor
- the pickling jar shatters
- pickle juice gets everywhere
- your mom beats you
- your butt is sore

as a human, we take it granted that something like this chain of causation exists in our mind.

- running in the kitchen CAUSES your mom to warning you
- DESPITE mom's warning, you throw her pickling jar onto the floor
- the pickling jar hitting the floor CAUSES the jar to break
- the jar breaking CAUSES juice to get everywhere
- the jar breaking AND pickle juice getting everywhere JOINTLY AFFECT how hard your mom beats you
- beating CAUSES soreness

specifically, our common human experience tells us intuitively that, for example

- throwing the pickling jar CAUSES pickling to get everywhere ONLY THROUGH the jar breaking
- it being 8pm has no direct relation to your mom beating you - notably, she would've beat you for breaking her pickle jar at 7pm or 9pm all the same

On top of that, to really say we "understand" things, we'd be able to make predictions and counterfactuals such as

- Had I not thrown the jar onto the floor, then my mom wouldn't have beat me
- Had mom not warned me to leave the kitchen, then she probably wouldn't have beaten as hard

### seeing the world through computer vision

now, if you're anything like my mom when I presented her this argument, you would now be lamenting at how I'm wasting my time going over the painfully obvious...

but is this obvious to a computer.

Let's take a look at what this series of events would look like from the point of view of a computer.-

In other words, as a stream of zeros and ones at whatever sampling frequency our camera and microphone picks up data.

Looking at this input stream of zeros and ones, would we be able to get computer to somehow figure out what the appropriate output stream of zeros and ones needs to be in order that the robot arms and wheels don't result in any jars being broken in real life, and that if we ask the AI "how come you emitted this particular stream of 0s and 1s" that it can reply with the binary equivalent of "because I didn't want to be beaten"?

### breaking the problem down

Solving _all_ of this is literally beyond the scope of what's currently artifically 
